# ğŸ§  Cognitive Load Assessment via 3D-CNN

### *Real-time NASA-TLX Prediction from Facial Video*

---

This project introduces a **non-intrusive method** to estimate cognitive load from facial videos. Using **MediaPipe Face Mesh** for landmark extraction and a **3D-CNN** for spatiotemporal modeling, the system predicts the five NASA-TLX subscales in real time. 

- ğŸ¯ Real-time inference from video streams
- ğŸ” Explainability with **SHAP** to reveal important facial regions
- âš¡ End-to-end efficient pipeline: landmarks â†’ features â†’ 3D-CNN â†’ interpretable outputs

---

## ğŸ“Š Performance

| Metric | Train | Test |
|--------|------:|----:|
| MAE    | 2.06  | 3.11 |
| RÂ²     | 0.71  | 0.43 |

---

## ğŸ“‚ Data Structure

```
data/
â”œâ”€â”€ raw/
â”‚   â””â”€â”€ {participant_id}/video.mp4
â”œâ”€â”€ landmarks184/
â””â”€â”€ labels/labels.csv
```

---

## ğŸ§¬ Model Architecture

- **Input**: Preprocessed landmark tensors (120 Ã— 16 Ã— 12 Ã— 1)
- **Layers**: Stacked Conv3D blocks + MaxPooling + Dense regression head
- **Output**: Predicted scores for the 5 NASA-TLX subscales

---

## ğŸ“ Key Insights

- **Eyes** â†’ attention & focus
- **Forehead** â†’ concentration via muscle tension
- **Chin/Neck** â†’ posture & stress indicators
- **Mouth** â†’ speech-related effort
- **Cheeks** â†’ subtle emotional strain

---

## âš™ï¸ Quick Start

### Installation
```bash
python -m venv venv
source venv/bin/activate   # or venv\\Scripts\\activate on Windows
pip install -r requirements.txt
```

### Training
```bash
python train_3dcnn_tlx.py \
  --data_dir data/landmarks184 \
  --labels data/labels/labels.csv \
  --split subject \
  --epochs 100 \
  --batch 16
```

### Explainability
```bash
python shap_explain_tlx.py \
  --checkpoint outputs/checkpoints/best.ckpt \
  --data_dir data/landmarks184 \
  --out_dir outputs/shap
```

---

## ğŸ“„ License & Ethics

- Informed consent obtained from all participants
- Biometric data must be handled responsibly
- Code is open-sourced under **MIT License**

---

